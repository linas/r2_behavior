#!/usr/bin/env python
PACKAGE = 'r2_behavior'

from dynamic_reconfigure.parameter_generator_catkin import *
import yaml_config

gen = ParameterGenerator()

gen.add("enable_flag", bool_t, 0, "enable behaviors", True)
gen.add("synthesizer_rate",double_t,0,"rate at which behavior is synthesized (Hz)",10.0,0.0,100.0)

eye_contact_enum = gen.enum([
  gen.const("IDLE",int_t,0,"IDLE: do not make eye contact"),
  gen.const("LEFT_EYE",int_t,1,"LEFT_EYE: look at left eye"),
  gen.const("RIGHT_EYE",int_t,2,"RIGHT_EYE: look at right eye"),
  gen.const("BOTH_EYES",int_t,3,"BOTH_EYES: switch between looking at left eye and right eye"),
  gen.const("TRIANGLE",int_t,4,"TRIANGLE: switch between looking at left eye, right eye and mouth")
],"eye contact state")

gen.add("eyecontact_state",int_t,0,"eye contact state",0,0,4,edit_method=eye_contact_enum)

lookat_enum = gen.enum([
  gen.const("IDLE",int_t,0,"IDLE: not looking at anything"),
  gen.const("AVOID",int_t,1,"AVOID: avoid looking at anything"),
  gen.const("SALIENCY",int_t,2,"SALIENCY: look at generally interesting things"),
  gen.const("HAND",int_t,3,"HAND: look at a hand"),
  gen.const("ONE_FACE",int_t,4,"ONE_FACE: look at the current face"),
  gen.const("ALL_FACES",int_t,5,"ALL_FACES: switch between looking at all faces"),
  gen.const("AUDIENCE",int_t,6,"AUDIENCE: switch between looking at the audience"),
  gen.const("SPEAKER",int_t,7,"SPEAKER: look at the speaker")
],"lookat state")

gen.add("lookat_state",int_t,0,"lookat state",0,0,7,edit_method=lookat_enum)

state_enum = gen.enum([
  gen.const("SLEEPING",int_t,0,"SLEEPING: the robot sleeps"),
  gen.const("IDLE",int_t,1,"IDLE: the robot is idle"),
  gen.const("INTERESTED",int_t,2,"INTERESTED: the robot is actively idle"),
  gen.const("FOCUSED",int_t,3,"FOCUSED: the robot is very interested in something specific"),
  gen.const("SPEAKING",int_t,4,"SPEAKING: the robot is to one or more persons or the speaker"),
  gen.const("LISTENING",int_t,5,"LISTENING: the robot is listening to whoever is speaking"),
  gen.const("PRESENTING",int_t,6,"PRESENTING: the robot is presenting to an audience")
],"main state")


gen.add("state",int_t,0,"main robot state (controls the other states)",1,0,6,edit_method=state_enum)

gen.add("saliency_counter_min",int_t,0,"minimum number of ticks between each saliency switch (@ synthesizer_rate)",1,1,30)
gen.add("saliency_counter_max",int_t,0,"maximum number of ticks between each saliency switch (@ synthesizer_rate)",1,1,30)
gen.add("faces_counter_min",int_t,0,"minimum number of ticks between each face switch (@ synthesizer_rate)",1,1,30)
gen.add("faces_counter_max",int_t,0,"maximum number of ticks between each face switch (@ synthesizer_rate)",1,1,30)
gen.add("eyes_counter_min",int_t,0,"minimum number of ticks between each eye switch (@ synthesizer_rate)",1,1,30)
gen.add("eyes_counter_max",int_t,0,"maximum number of ticks between each eye switch (@ synthesizer_rate)",1,1,30)
gen.add("audience_counter_min",int_t,0,"minimum number of ticks between each audience switch (@ synthesizer_rate)",1,1,30)
gen.add("audience_counter_max",int_t,0,"maximum number of ticks between each audience switch (@ synthesizer_rate)",1,1,30)
gen.add("keep_time",double_t,0,"time to keep observations around as useful (sec)",0.5,0.01,10.0)

gen.add("sleeping_gestures_schema", str_t, 0, 'SLEEPING gestures', yaml_config.parse('gestures_schema' or '{}'))
gen.add("sleeping_expressions_schema", str_t, 0, 'SLEEPING expressions', yaml_config.parse('expressions_schema' or '{}'))

gen.add("idle_gestures_schema", str_t, 0, 'IDLE gestures', yaml_config.parse('gestures_schema' or '{}'))
gen.add("idle_expressions_schema", str_t, 0, 'IDLE expressions', yaml_config.parse('expressions_schema' or '{}'))

gen.add("interested_gestures_schema", str_t, 0, 'INTERESTED gestures', yaml_config.parse('gestures_schema' or '{}'))
gen.add("interested_expressions_schema", str_t, 0, 'INTERESTED expressions', yaml_config.parse('expressions_schema' or '{}'))

gen.add("focused_gestures_schema", str_t, 0, 'FOCUSED gestures', yaml_config.parse('gestures_schema' or '{}'))
gen.add("focused_expressions_schema", str_t, 0, 'FOCUSED expressions', yaml_config.parse('expressions_schema' or '{}'))

gen.add("speaking_gestures_schema", str_t, 0, 'SPEAKING gestures', yaml_config.parse('gestures_schema' or '{}'))
gen.add("speaking_expressions_schema", str_t, 0, 'SPEAKING expressions', yaml_config.parse('expressions_schema' or '{}'))

gen.add("listening_gestures_schema", str_t, 0, 'LISTENING gestures', yaml_config.parse('gestures_schema' or '{}'))
gen.add("listening_expressions_schema", str_t, 0, 'LISTENING expressions', yaml_config.parse('expressions_schema' or '{}'))

gen.add("presenting_gestures_schema", str_t, 0, 'PRESENTING gestures', yaml_config.parse('gestures_schema' or '{}'))
gen.add("presenting_expressions_schema", str_t, 0, 'PRESENTING expressions', yaml_config.parse('expressions_schema' or '{}'))

exit(gen.generate(PACKAGE, "behavior", "Behavior"))
